# üìò Base Scraper Architecture & Documentation

**D·ª± √°n:** Vietnam IT Market Analysis & Salary Prediction  
**Module:** Data Collection (Scraping Core)  
**Phi√™n b·∫£n:** 1.0  
**Ng√†y c·∫≠p nh·∫≠t:** 29/01/2026

***

## 1. T·ªïng quan (Overview)

File `base_scraper.py` ch·ª©a class `BaseScraper`. ƒê√¢y l√† l·ªõp cha (Parent Class) tr·ª´u t∆∞·ª£ng, ƒë√≥ng vai tr√≤ l√† x∆∞∆°ng s·ªëng cho to√†n b·ªô h·ªá th·ªëng c√†o d·ªØ li·ªáu.

**M·ª•c ƒë√≠ch:**
1. **Qu·∫£n l√Ω k·∫øt n·ªëi t·∫≠p trung:** X·ª≠ l√Ω k·∫øt n·ªëi MongoDB Atlas, b·∫£o m·∫≠t SSL v√† x√°c th·ª±c.
2. **Chu·∫©n h√≥a d·ªØ li·ªáu:** ƒê·∫£m b·∫£o m·ªçi d·ªØ li·ªáu c√†o v·ªÅ ƒë·ªÅu c√≥ ƒë·ªß si√™u d·ªØ li·ªáu (metadata) nh∆∞ ngu·ªìn, ng√†y c√†o.
3. **X·ª≠ l√Ω l·ªói:** T·ª± ƒë·ªông b·∫Øt l·ªói tr√πng l·∫∑p (`DuplicateKeyError`) ƒë·ªÉ scraper kh√¥ng b·ªã d·ª´ng ƒë·ªôt ng·ªôt.

***

## 2. C√°c th∆∞ vi·ªán s·ª≠ d·ª•ng (Dependencies)

Gi·∫£i th√≠ch l√Ω do t·∫°i sao d·ª± √°n s·ª≠ d·ª•ng c√°c th∆∞ vi·ªán n√†y:

| Th∆∞ vi·ªán     | Vai tr√≤ & L√Ω do s·ª≠ d·ª•ng |
|--------------|-------------------------|
| **`abc`** (Abstract Base Class) | T·∫°o ra m·ªôt "khu√¥n m·∫´u" b·∫Øt bu·ªôc. N√≥ √©p bu·ªôc c√°c class con (nh∆∞ `ITViecScraper`) ph·∫£i vi·∫øt h√†m `scrape()`, gi√∫p code ƒë·ªìng b·ªô. |
| **`pymongo`** | Driver ch√≠nh th·ª©c ƒë·ªÉ Python giao ti·∫øp v·ªõi MongoDB. D√πng ƒë·ªÉ g·ª≠i l·ªánh `insert`, `find` t·ªõi Database. |
| **`certifi`** | **Quan tr·ªçng:** Cung c·∫•p ch·ª©ng ch·ªâ b·∫£o m·∫≠t (Root CA) m·ªõi nh·∫•t. Gi√∫p kh·∫Øc ph·ª•c l·ªói `SSL handshake failed` khi k·∫øt n·ªëi MongoDB Atlas t·ª´ m√°y c√° nh√¢n/Windows. |
| **`logging`** | Ghi nh·∫≠t k√Ω ho·∫°t ƒë·ªông (`INFO`, `ERROR`, `WARNING`) thay v√¨ d√πng `print`. Gi√∫p debug l·ªói hi·ªáu qu·∫£ v√† chuy√™n nghi·ªáp h∆°n. |
| **`dotenv`** | B·∫£o m·∫≠t. D√πng ƒë·ªÉ ƒë·ªçc m·∫≠t kh·∫©u DB t·ª´ file `.env` thay v√¨ vi·∫øt c·ª©ng (hardcode) trong code. |
| **`datetime`** | L·∫•y th·ªùi gian th·ª±c ƒë·ªÉ g·∫Øn nh√£n th·ªùi gian (`crawled_date`) cho d·ªØ li·ªáu. |

***

## 3. Chi ti·∫øt c√°c h√†m & Input (Function Specifications)

D∆∞·ªõi ƒë√¢y l√† t√†i li·ªáu chi ti·∫øt v·ªÅ c√°c h√†m trong class, ƒë·∫∑c bi·ªát l√† √Ω nghƒ©a c·ªßa c√°c tham s·ªë ƒë·∫ßu v√†o (Input).

### 3.1. H√†m kh·ªüi t·∫°o `__init__`

D√πng ƒë·ªÉ thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng v√† k·∫øt n·ªëi Database ngay khi Scraper ƒë∆∞·ª£c b·∫≠t l√™n.

```python
def __init__(self, source_name, db_name="VietnamITMarket", collection_name="raw_jobs"):
```

| Tham s·ªë (Input) | Ki·ªÉu d·ªØ li·ªáu | B·∫Øt bu·ªôc? | M√¥ t·∫£ & T√°c d·ª•ng |
|-----------------|--------------|-----------|------------------|
| `source_name`   | `str`        | ‚úÖ C√≥     | T√™n ngu·ªìn d·ªØ li·ªáu. (VD: "ITviec", "TopCV"). D√πng ƒë·ªÉ ph√¢n lo·∫°i d·ªØ li·ªáu trong Database v√† t·∫°o Logger ri√™ng bi·ªát. |
| `db_name`       | `str`        | ‚ùå Kh√¥ng  | T√™n Database tr√™n MongoDB. M·∫∑c ƒë·ªãnh l√† "VietnamITMarket". |
| `collection_name` | `str`     | ‚ùå Kh√¥ng  | T√™n Collection (b·∫£ng) l∆∞u tr·ªØ. M·∫∑c ƒë·ªãnh l√† "raw_jobs". |

### 3.2. H√†m l∆∞u d·ªØ li·ªáu `save_job`

H√†m quan tr·ªçng nh·∫•t ƒë·ªÉ ƒë∆∞a d·ªØ li·ªáu v√†o kho. Class con s·∫Ω g·ªçi h√†m n√†y sau khi c√†o xong 1 tin tuy·ªÉn d·ª•ng.

```python
def save_job(self, job_data):
```

| Tham s·ªë (Input) | Ki·ªÉu d·ªØ li·ªáu      | M√¥ t·∫£ chi ti·∫øt |
|-----------------|--------------------|----------------|
| `job_data`      | `dict` (Dictionary) | G√≥i tin ch·ª©a th√¥ng tin vi·ªác l√†m. ƒê√¢y l√† d·ªØ li·ªáu th√¥ m√† Scraper con thu th·∫≠p ƒë∆∞·ª£c. |

**C·∫•u tr√∫c b·∫Øt bu·ªôc c·ªßa `job_data` (Input Schema):**

ƒê·ªÉ h√†m n√†y ho·∫°t ƒë·ªông, dictionary `job_data` ƒë·∫ßu v√†o ph·∫£i ch·ª©a √≠t nh·∫•t c√°c tr∆∞·ªùng sau:
- `url` (B·∫Øt bu·ªôc): Link g·ªëc c·ªßa b√†i ƒëƒÉng (D√πng l√†m kh√≥a ch√≠nh ƒë·ªÉ ch·ªëng tr√πng).
- `job_title`: T√™n c√¥ng vi·ªác.
- `company_name`: T√™n c√¥ng ty.
- (C√°c tr∆∞·ªùng kh√°c nh∆∞ `salary`, `skills`... c√≥ th·ªÉ c√≥ ho·∫∑c kh√¥ng)

**Logic x·ª≠ l√Ω b√™n trong:**
- G·∫Øn Metadata: T·ª± ƒë·ªông th√™m `source` (l·∫•y t·ª´ init) v√† `crawled_date` (gi·ªù hi·ªán t·∫°i) v√†o `job_data`.
- Validate: Ki·ªÉm tra xem c√≥ `url` kh√¥ng. N·∫øu kh√¥ng c√≥ -> H·ªßy l∆∞u.
- Insert: Th·ª≠ l∆∞u v√†o DB. N·∫øu tr√πng URL -> B√°o Log Warning v√† b·ªè qua.

### 3.3. H√†m tr·ª´u t∆∞·ª£ng `scrape`

H√†m n√†y ch∆∞a c√≥ n·ªôi dung (logic r·ªóng).

```python
@abstractmethod
def scrape(self):
```

**Input:** Kh√¥ng c√≥ (ho·∫∑c t√πy bi·∫øn ·ªü class con).  
**T√°c d·ª•ng:** ƒê√¢y l√† m·ªôt "l·ªùi h·ª©a". B·∫•t k·ª≥ class n√†o k·∫ø th·ª´a `BaseScraper` ƒë·ªÅu **B·∫ÆT BU·ªòC** ph·∫£i vi·∫øt code cho h√†m n√†y. N·∫øu kh√¥ng, ch∆∞∆°ng tr√¨nh s·∫Ω b√°o l·ªói.

***

## 4. H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng (Implementation Guide)

D√†nh cho Developer (Dev A, Dev B...) khi t·∫°o Scraper m·ªõi.

### B∆∞·ªõc 1: T·∫°o file `.env` (B·∫£o m·∫≠t)

T·∫°o file `.env` t·∫°i th∆∞ m·ª•c g·ªëc ch·ª©a chu·ªói k·∫øt n·ªëi:

```
MONGO_URI=mongodb+srv://<user>:<password>@cluster.mongodb.net/
```

### B∆∞·ªõc 2: Vi·∫øt code k·∫ø th·ª´a

V√≠ d·ª• t·∫°o file `scrapers/itviec_scraper.py`:

```python
from base_scraper import BaseScraper

class ITViecScraper(BaseScraper):
    def __init__(self):
        # G·ªçi h√†m kh·ªüi t·∫°o c·ªßa cha, ƒë·∫∑t t√™n ngu·ªìn l√† "ITviec"
        super().__init__(source_name="ITviec")

    # B·∫ÆT BU·ªòC PH·∫¢I VI·∫æT H√ÄM NAY
    def scrape(self):
        self.logger.info("ƒêang b·∫Øt ƒë·∫ßu c√†o ITviec...")
        
        # ... (Vi·∫øt code BeautifulSoup/Selenium ·ªü ƒë√¢y) ...
        
        # Gi·∫£ s·ª≠ l·∫•y ƒë∆∞·ª£c 1 job:
        my_job = {
            "url": "https://itviec.com/job/python-dev",
            "job_title": "Python Developer",
            "company_name": "FPT Software"
        }

        # G·ªçi h√†m c·ªßa cha ƒë·ªÉ l∆∞u
        self.save_job(my_job)

# Ch·∫°y th·ª≠
if __name__ == "__main__":
    bot = ITViecScraper()
    bot.scrape()
```

***

## 5. C√°c l·ªói th∆∞·ªùng g·∫∑p (Troubleshooting)

| L·ªói                    | Nguy√™n nh√¢n                          | C√°ch s·ª≠a |
|------------------------|--------------------------------------|----------|
| `SSL handshake failed` | M√°y thi·∫øu ch·ª©ng ch·ªâ b·∫£o m·∫≠t.         | Ki·ªÉm tra xem ƒë√£ import `certifi` v√† th√™m `tlsCAFile=certifi.where()` trong `BaseScraper` ch∆∞a. |
| `Can't instantiate abstract class` | Class con ch∆∞a vi·∫øt h√†m `scrape`. | Ki·ªÉm tra class con, ƒë·ªãnh nghƒ©a l·∫°i h√†m `def scrape(self):`. |
| `DuplicateKeyError`    | URL ƒë√£ t·ªìn t·∫°i trong DB.             | Kh√¥ng c·∫ßn s·ª≠a. ƒê√¢y l√† t√≠nh nƒÉng ch·ªëng tr√πng l·∫∑p. Log s·∫Ω hi·ªán m√†u v√†ng (Warning). |
| `Authentication failed` | Sai User/Pass trong `MONGO_URI`.    | Ki·ªÉm tra l·∫°i file `.env`, ƒë·∫£m b·∫£o m·∫≠t kh·∫©u kh√¥ng ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát g√¢y l·ªói URL. |